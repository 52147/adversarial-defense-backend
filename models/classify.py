import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
import io
import urllib.request

# âœ… Google Drive ä¸‹è¼‰ URL
MODEL_URL = "https://drive.google.com/uc?id=13D1bcxVFpuMY62UrjXPBuULnfJglQIIm&export=download"

# âœ… å®šç¾© SimpleCNN
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 64 * 7 * 7)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)

# âœ… ç›´æ¥å¾ Google Drive åŠ è¼‰æ¨¡å‹
def load_model_from_drive():
    print("ğŸš€ ç›´æ¥å¾ Google Drive åŠ è¼‰æ¨¡å‹...")
    try:
        response = urllib.request.urlopen(MODEL_URL)  # è®€å– `.pth` æ–‡ä»¶
        model_data = io.BytesIO(response.read())  # è½‰ç‚ºè¨˜æ†¶é«”æµ
        model = SimpleCNN()
        model.load_state_dict(torch.load(model_data, map_location=torch.device("cpu")))
        model.eval()
        print("âœ… æˆåŠŸç›´æ¥å¾ Google Drive åŠ è¼‰æ¨¡å‹ï¼")
        return model
    except Exception as e:
        print(f"âŒ ç„¡æ³•å¾ Google Drive åŠ è¼‰æ¨¡å‹ï¼éŒ¯èª¤: {e}")
        raise e  # è®“ç¨‹åºçµ‚æ­¢

# âœ… åŠ è¼‰æ¨¡å‹
model = load_model_from_drive()

# âœ… åœ–ç‰‡è½‰æ›å‡½æ•¸
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((28, 28)),  # MNIST åœ–åƒå¤§å°
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

def classify_image(image):
    """
    âœ… `classify_image()` ç¾åœ¨åªéœ€è¦ **åœ–ç‰‡ä½œç‚ºåƒæ•¸**
    """
    if isinstance(image, str):  # å¦‚æœæ˜¯è·¯å¾‘ï¼Œå…ˆè®€å–åœ–ç‰‡
        image = Image.open(image).convert("L")  

    image = transform(image).unsqueeze(0)  # å¢åŠ  batch ç¶­åº¦
    with torch.no_grad():
        output = model(image)
        pred = output.argmax(dim=1, keepdim=True).item()
    
    return pred  # è¿”å›é æ¸¬æ•¸å­—